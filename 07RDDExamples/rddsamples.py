from pyspark import SparkContext, SparkConf, SQLContext
conf = SparkConf().setAppName("RDD").setMaster("local[2]")
sc = SparkContext(conf=conf)
sqlContext = SQLContext(sc)
# Create RDDs
lines = sc.textFile("data/PoemsByKeats.txt")
airports = sc.textFile("data/airports.text")
myRDD = sc.textFile('data/airport-codes-na.txt')
myRDD.take(5)
myRDD.count()
sc.textFile('data/airport-codes-na.txt').map(lambda line: line.split("\t"))
myRDD.getNumPartitions()
myRDD = sc.textFile('data/airport-codes-na.txt', minPartitions=4, use_unicode=True).map(lambda line: line.split("\t"))
myRDD.take(5)
myRDD.getNumPartitions()
myRDD = sc.textFile('data/departuredelays.csv').map(lambda line: line.split(","))
myRDD.count()
myRDD = sc.textFile('data/departuredelays.csv', minPartitions=8).map(lambda line: line.split(","))
myRDD.count()
myRDD.take(5)
myRDD.getNumPartitions()
myDF = sqlContext.read.format("com.databricks.spark.csv").option("delimiter", ",").option("header", 'true').option("inferschema",'true').load("data/departuredelays.csv")
myDF.count()
myDF.show()
myDF.rdd.getNumPartitions()
myDF.printSchema()
airports = sc.textFile('data/airport-codes-na.txt').map(lambda line: line.split("\t"))
airports.take(5)
flights = sqlContext.read.format("com.databricks.spark.csv").option("delimiter", ",").option("header", 'true').option("inferschema",'true').load("data/departuredelays.csv")
flights.take(5)
# Count Example
lineLengths = lines.map(lambda s: len(s))
totalLength = lineLengths.reduce(lambda a, b: a + b)
print("Line count: ", totalLength)
airportsInUSA = airports.filter(lambda line :  line.split(' ')(6).toFloat > 40)
airportsNameAndCityNames = airportsInUSA.map(lambda line : line.split(' ').splits(1))
#airportsNameAndCityNames.saveAsTextFile("output/airports_by_latitude.txt")

# Map Example Map
lineLengths = airports.count()

# Example for map()
print(airports.map(lambda c: (c[0], c[1])).take(5))
# Example for filter()
print(airports.map(lambda c: (c[0], c[1])).filter(lambda c: c[1] == "WA").take(5))
# Example for  flatMap()
print(airports.filter(lambda c: c[1] == "WA").map(lambda c: (c[0], c[1])).flatMap(lambda x: x).take(10))
# Example for distinct()
print(airports.map(lambda c: c[2]).distinct().take(5))
# Example for sample()
flights = sc.textFile('data/departuredelays.csv').map(lambda line: line.split(","))
print(flights.map(lambda c: c[3]).sample(False, 0.001, 123).take(5))
# Example for leftOuterJoin()
flights.map(lambda c: (c[3], c[0])).take(5)
print(flights.take(5))
airports.map(lambda c: (c[3], c[1])).take(5)
flt = flights.map(lambda c: (c[3], c[0]))
air = airports.map(lambda c: (c[3], c[1]))
print(flt.join(air).take(5))
flt = flights.map(lambda c: (c[3], c[0]))
air = airports.map(lambda c: (c[3], c[1]))
print(flt.join(air))
# Example for repartition()
flights.getNumPartitions()
flights2 = flights.repartition(8)
flights2.getNumPartitions()
print(flights2)
